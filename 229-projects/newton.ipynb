{"worksheets":[{"cells":[{"cell_type":"markdown","source":"Questions to be handed in on Newton's Method:\n=============================================\nBegin by loading our package for plotting and the Roots package\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"using Gadfly            \nusing Roots","collapsed":"false"},{"cell_type":"markdown","source":"* * * * *\n### Quick background\n\nRead about this material here: [Newton's\nMethod](http://mth229.github.io/newton.html).\n\nFor the impatient, symbolic math -- as is done behind the scenes at the\nWolfram alpha web site -- is pretty nice. For so many problems it can\neasily do what is tedious work. However, for some questions, only\nnumeric solutions are possible. For example, there is no general formula\nto solve a fifth order polynomial, the way there is a quadratic formula.\nEven an innocuous polynomial like $f(x) = x^5 - x - 1$ has no easy\nalgebraic solution:\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"import SymPy            # a symbolic math program\nx = SymPy.Sym(\"x\")\nSymPy.solve(x^5 - x - 1)","collapsed":"false"},{"cell_type":"markdown","source":"We see that `SymPy` basically punts on this question.\nNumeric solutions are available. As this is a polynomial, we could use\nthe `roots` function:\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"f(x) = x^5 - x - 1\nroots(f)","collapsed":"false"},{"cell_type":"markdown","source":"We see 5 roots -- as expected from a fifth degree polynomial -- with one\nreal root (the one with `0.0im`) that is approximately 1.1673. Finding\nsuch a value usually requires some iterative root-finding algorithm\n(though not in the case above which uses linear algebra).\nNewton's method is a root-finding algorithm like the bisection method\ndiscussed earlier. As an *iterative algorithm* it starts with some\n*guess* for a *root* to an equation $f(x) = 0$. If this guess is called\n$x_0$, then the algorithm gives a *new (and improved)* guess $x_1$. It\nis expected that $x_1$ is a better guess, but may not be the best that\ncan be. The algorithm is then repeated *again* to produce $x_2$. This is\ndone until some guess $x_n$ is as close as we can get or the algorithm\nfails for some reason. The *approximate root* is taken to be $x_n$.\n\nWhat is the algorithm? It is simple. If we start with some $x_i$, then\n$x_{i+1}$ is given by the intersection point of the $x$-axis of the\ntangent line of $f(x)$ at $x_i$. (See the notes for a figure.)\nMathematically then we can equate our two methods to compute the slope\nof a tangent line:\n\n$$\nf'(x_i) = \\frac{f(x_i) - 0}{x_i - x_{i+1}}\n$$\n\nOr, solving for $x_{i+1}$:\n\n$$\nx_{i+1} = x_i - f(x_i)/f'(x_i)\n$$\n\nLet's see this algorithm for `f(x) = x^3−2x−5`, a function that Newton\nconsidered. He was looking for a solution near $2$, so let's start\nthere:\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"x = 2\nf(x) = x^3 - 2x -5\nfp(x) = 3x^2 - 2        # done by hand","collapsed":"false"},{"cell_type":"markdown","source":"We don't need to track the index ($x_0$, $x_1$, ...) as when we write\nthe following expression, the next value is just assigned to `x` using\nthe *current* value of `x` when computed:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"x = x - f(x) / fp(x)\nx, f(x)             # display both the new guess, x,  and the value f(x)","collapsed":"false"},{"cell_type":"markdown","source":"The value of $2.1$ is a better guess, but not near the actual answer. We\nsimply repeat to (hopefully) get a better guess:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"x = x - f(x) / fp(x)\nx, f(x)","collapsed":"false"},{"cell_type":"markdown","source":"Here are a few repeats:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"x = x - f(x) / fp(x)\nx, f(x)","collapsed":"false"},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"x = x - f(x) / fp(x)\nx, f(x)","collapsed":"false"},{"cell_type":"markdown","source":"The value of `f(x)` is now *basically* 0, and any further updates to `x`\ndo not change its value. We see that the algorithm has converged to an\nanswer, `x`, and the fact that it is a zero is confirmed by the value of\n`f(x)`.\nRepeating steps in `IJulia` can be a bit of a chore, so here we define a\n*macro* to repeat some expression 5 times and then show how to use it.\n(This macro basically replaces the expression internally with 5 repeats\nof the expression.)\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"macro take5(body) quote Float64[$(esc(body)) for _ in 1:5] end end # take5 macro","collapsed":"false"},{"cell_type":"markdown","source":"Macros are prefaced with a `@` in their name and are typically called\nwithout parentheses:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"x = 2               # starting value\n@take5     x = x - f(x) / fp(x)","collapsed":"false"},{"cell_type":"markdown","source":"and to see that `x` has been updated we have:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"x, f(x)","collapsed":"false"},{"cell_type":"markdown","source":"### Questions\n-   Apply Newton's Method to the function $f(x) = \\sin(x)$ with an\n    initial guess $3$. (This was historically used to compute many\n    digits of $\\pi$ efficiently.) What is the answer after 5 iterations?\n    What is the value of `sin` at the answer?\n\nThe value of $f(x)$ after 5 iterations is:\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"The value of $f(x)=\\sin(x)$ at this approximate zero:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"-   Use Newton's method to find a zero for the function $f(x)=x^5-x-1$.\n    Start at $x=1.6$. What is the approximate root after 5 iterations?\n    What is the value of $f(x)$ for your answer? If you do one or two\n    more iterations, will your guess be better?\n\nThe value after 5 iterations\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"The value of $f(x)$:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"The value after two more iterations:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"-   Use Newton's method to find a zero of the function\n    $f(x) = \\cos(x) -   x$. Make a graph to identify an initial guess.\n\nShow your commands below\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"The value of the approximate zero:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"### Using `D` for the derivative\nIf the function `f(x)` allows it, the `D` operator from the `Roots`\npackage can simplify the Newton's method algorithm, as the derivative\nneed not be computed by hand. In this case, the algorithm in `julia`\nbecomes `x = x - f(x)/D(f)(x)`.\n\n-   Use Newton's method to find an intersection point of\n    $f(x) =   e^{-x^2}$ and $g(x)=x$. (Look at\n    $h(x) = f(x) - g(x) = 0$.) Start with a guess of $0$.\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"-   Use Newton's method to find *both* positive intersection point of\n    $f(x) = e^x$ and $g(x) = 2x^2$. Make a graph to identify good\n    initial guesses.\n\nThe smallest value is:\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"The largest value is:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"### Using `newton` and `fzero` from the `Roots` package\nThe `newton` function in the `Roots` package will compute newton's\nmethod. For example:\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"f(x) = sin(x)\nfp(x) = cos(x)\nx = 3\nnewton(f, fp, x)","collapsed":"false"},{"cell_type":"markdown","source":"The extra argument `verbose=true` will show the iterations:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"newton(f, fp, 3, verbose=true)","collapsed":"false"},{"cell_type":"markdown","source":"However, the `fzero` function -- that we have seen before -- will use a\nderivative-free algorithm, similar to Newton's method to find a zero.\nSo, the above zero can also be found with:\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"fzero(sin, 3)","collapsed":"false"},{"cell_type":"markdown","source":"(That is right, `fzero` can be used two different ways -- at least.\nAbove it is called with an initial guess. Previously, we called it with\na bracketing interval, as in `fzero(sin, [3,4])`. If you specify a\nbracketing interval, `fzero` will use an algorithm guaranteed to\nconverge. If you just specify an initial guess, the convergence is\ngenerally faster, but may not happen.)\n* * * * *\n\n-   find a zero of $f(x) = x\\cdot (2+\\ln(x))$ starting at $1$. What is\n    your answer? How small is the function for this value?\n\nWhat is the value of the zero?\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"The value of the function at the zero?\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"-   Use `fzero` to find all zeros of the function\n    $f(x) = 2\\sin(x) -   \\cos(2x)$ in $[0, 2\\pi]$. (Graph first to see\n    approximate answers.)\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"-   Use `fzero` to find when the derivative of\n    $f(x) = 5/\\cos(x) +   7/\\sin(x)$ is $0$ in the interval\n    $(0, \\pi/2)$.\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"### When Newton's method fails\nNewton's method can fail due to various cases:\n\n1)  the initial guess is not close to the zero\n\n2)  the derivative, $|f'(x)|$ is too small\n\n3)  the second derivative $|f''(x)|$ is too big\n\n\n-   Let $f(x) = x^5 - x - 1$. Try Newton's method with an initial guess\n    of $x_0=0$. Why does this fail? (You can look graphically.\n    Otherwise, you could look at the output of `newton` with this extra\n    argument: `newton(f, fp, x0, verbose=true)`.\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"-   Let `f(x) = abs(x)^(1/3)`. Starting at `x=1`, Newton's method will\n    fail to converge. What happens? Are any of the above 3 reason's to\n    blame?\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"### Quadratic convergence\nWhen Newton's method converges to a *simple zero* it is said to have\n*quadratic convergence*. A simple zero is one with multiplicity 1 and\nquadratic convergence says basically that the error at the $i+1$st step\nis like the error for $i$th step squared. In particular, if the error is\nlike $10^{-3}$ on one step, it will be like $10^{-6}$, then $10^{-12}$\nthen $10^{-24}$ on subsequent steps. (Which is typically beyond the\nlimit of a floating point approximation.) This is why one can *usually*\ntake just 5 steps to get to an answer.\n\nNot so for multiple roots.\n\n-   For the function `f(x) = (8x*exp(-x^2) -2x - 3)^8`, starting with\n    `x=-2.0` Newton's method will converge, but it will take many steps\n    to get to an answer that has $f(x)$ around $10^{-16}$. How many?\n    Roughly how many iterations do you need? (A single call of\n    `@take5 x = x-f(x)/D(f)(x)` gives an answer with `f(x) = 0.00028`\n    only.)\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"},{"cell_type":"markdown","source":"-   Repeat the above with `f(x) = 8x*exp(-x^2) -2x - 3` -- there is no\n    extra power of $8$ here -- and again, starting with `x=-2.0`.\n    Roughly how many iterations are needed now?\n\n","metadata":{}},{"outputs":[],"cell_type":"code","languge":"python","metadata":{},"input":"","collapsed":"false"}],"metadata":{}}],"nbformat_minor":0,"metadata":{"name":"TITLE","language":"Julia"},"nbformat":3}