## Solving for zeros with julia



```{hide=true, display=false, results="none"}
using Weave
tabs = tabbable()
```

```{hide=true, results="js"}
using Gadfly
Gadfly.prepare_display()
```


```{results="html"}
tabs.start()
tabs.next("Introduction")
```

Solving for zero is a mathematical skill taught early on. In some
cases, such as with linear equations, solving for zeros can be done
directly using algebra. Similarly, in the case of factorable
polynomials, we are taught to factor and then set each term to 0 to
find the possible solutions, utilizing the fact that for the real
numbers the product of two numbers is $0$ only if one or both of the
numbers is as well.

However, in general, the problem of finding one
(or all) solutions to the equation

$$
f(x) = 0.
$$

for an arbitrary $f$ has no well-defined process.  

A related problem is to find one (or all) solutions to an equation of
this type:

$$
f(x) = g(x)
$$

Conceptually this is identical to the above, as we just set $h(x) =
f(x) - g(x)$ and solve for when $h(x)$ is $0$.


Here we discuss a few different elementary means to do find zeros with
`julia`, leaving some others for a later time. 


We will use the add-on package `Roots`, which provides a few root-finding algorithms:

```
using Roots			# must be installed first
```


```{results="html"}
tabs.next("Polynomials")
```


## Zeros of a polynomial


Polynomials are special functions, in that their relatively simple
form allows for many explicit things to be known. A famous example is
the **quadratic formula** which for polynomials of degree 2 gives an
explicit formula for the _roots_:

$$
\frac{-b \pm \sqrt{b^2 - 4ac}}{2a}.
$$


```{results="html"}
alert("""

A "root" of a polynomial is just a polynomial-specific
name for a zero.

""")
```


For example, if we have the quadratic polynomial $2x^2 + 3x - 2$ we can solve
for the roots with:

```
a = 2; b = 3; c = -2
discr = b^2 - 4*a*c
(-b + sqrt(discr))/(2a), (-b - sqrt(discr))/(2a) 
```


If you wanted to write a function to do this, it would be 
straightforward, save the detail of needing to make a negative number
complex in order to take its square root:

```
## find roots of ax^2 + bx + c
function quadratic(a, b, c)
  discr = b^2 - 4*a*c
  sq = (discr > 0) ? sqrt(discr) : sqrt(discr + 0im)

  [(-b - sq)/(2a), (-b + sq)/(2a)]
end
```

```{results="html"}
alert("""

This is an example where the function is not *type-stable* as it
returns either real-valued answers or complex-valued answers depending
on the *values* of the input variables.

""")
```


To find the roots of $x^2 + x - 1$ we could simply use:

```
quadratic(1, 1, -1)
```

There are also such formula for third and fourth degree
polynomials. However, Galois -- at the tender age of 20 -- demonstrated that,
in general, there can be no formula for the roots of a fifth or higher
degree polynomial. There are still facts known about such polynomials.
For example, the _Fundamental theorem of algebra_ states that every
real-valued polynomial of degree $n$ will have $n$ roots, where we count complex
roots and multiplicities.

How to find them is left to numeric methods though. In `julia` there
is an add-on package that will do this work for us. The actual code is
in the function `roots` from the `Polynomials` package, but we employ
the easier interface provided by the `Roots` package.


Rather than write the quadratic polynomial in terms of its
coefficients alone, we can pass in a quadratic function, as follows:



```
using Roots			# only needs to be done once per session
f(x) = x^2 + x - 1
roots(f)
```

That is, the command to find the roots of the polynomial $f(x)$ is simply
`roots` and the the function is called just by passing in the function name (or an anonymous function).

```{results="html"}
alert("""

This is another example of a general template **action(function_object,
args...)** for performing some action on a function. In this case, the
action is to find the roots of a function which specifies a polynomial
and the additional *args...* are not necessary.)

""")
```


That was so easy, we'll do it again. What are the roots of the
polynomial $f(x) = -16x^2 + 32x + 6$?

```
f(x) = -16x^2 + 32x + 6
roots(f)
```

What if the function has no real roots, as this polynomial?

```
f(x) = x^2 + x + 1
roots(f)
```

We see the answers are complex valued, as is necessary. 


The following polynomial has both real roots and complex roots:

```
f(x) = (x^2 + x + 1) * (x^2 + x - 1)
roots(f)
```

The returned value uses complex numbers, as that type is needed to
describe *all* four values that are returned. The two real roots (previously seen to be `-1.61803` and `0.618034`) are there, they have an additional `0.0im` added to them to make them complex values.

To get just the *real roots*, the related function `fzeros` can be used:

```
fzeros(f)			# just the real roots are returned
```


### Practice

#### Question

Find all roots of the function $f(x) = x^4 - 4x^2 -4x + 2$. Are they all real numbers?

```{results="js"}
choices = ["Yes, the are all real", "No, some are real, some are complex", "No, none are real"]
ans = 2
radioq(choices, ans)
```


#### Question

Use the `roots` command to find the largest real root of the
polynomial $x^2 + x - 5$


```{results="js"}
p = roots(x -> x^2 + x - 5)
val = maximum(p);
numericq(val, 1e-3)
```

#### Question

Use the `roots` command to find the largest real root of the polynomial $x^3 - x - 17$

```{results="js"}
zs = fzeros(x -> x^2 - x - 17);
val = maximum(zs)
numericq(val, 1e-3)
```


#### Question

[The rule of signs of Descartes](http://en.wikipedia.org/wiki/Descartes_rule_of_signs) 
is a simple means to give an upper bound on the number of positive real
roots a polynomial has. One counts the number of sign changes amongst
the polynomials coefficients. Suppose this is $k$, then the number of
*positive* real roots (counting multiplicities) is one of $k$, $k-2$,
$k-4$, ... . In particular if $k$ is odd, there must be at least one
real root.

For example, the polynomial $x^3 -x^2 -x - 1$ has signs `+---`, so
there is just one sign change. This implies there must be exactly one *positive*
real root, which is found with:

```
f(x) = x^3 -x^2 -x - 1
roots(f)
```




For the polynomial $f(x) = x^5 -x + 1$ has potentially 2 *positive*, real roots? Are there $0$ or $2$ positive, real roots?

```{results="js"}
choices = ["zero", "two"]
ans = 1
radioq(choices, ans)
```


#### Question

The number of possible *negative*, real roots can also be found from
Descartes' rule. Instead of looking at the sign changes of $f(x)$, one
must look at the sign changes of $g(x) = f(-x)$. 

If $f(x) = x^5 - x +1$ we have $g(x) = -x^5 +x + 1$ (just change the
signs of the coefficients of the odd powers). Then $g(x)$ has one sign
change. This means there is one *negative* real root. What is it?

```{results="js"}
val = fzeros(x -> x^5 - x +1)[1]
numericq(val, 1e-2)
```








```{results="html"}
tabs.next("Graphical solutions")
```

## Graphical solutions

More generally, the equation $f(x) = 0$ may not have any special form
leading to a known solution. In this case, there are various
techniques to find zeros. Here we mention graphing, such as is done
with a graphing calculator. In the next section, we discuss the
bisection algorithm for root finding.



```{results="js"}
example("Finding a zero")
```

The flight of an arrow can be modeled using various functions,
depending on assumptions. Suppose an arrow is launched in the air from
a height of 0 feet above the ground at an angle of $\theta =
\pi/4$. With a suitable choice for the initial velocity, a model
without wind resistance for the height of the arrow at a distance $x$
units away may be:

$$
j(x) = \tan(\theta) x- 16(\frac{x}{200 \cos\theta})^2.
$$

With a wind resistance given by $k$, again with some units, a similar
equation can be constructed. It takes a different form:

$$
g(x) = \tan(\theta) x +
     \frac{32/k}{200 \cos\theta} x -
    \frac{32}{k} \log\left(\frac{200 \cos\theta}{200\cos\theta - x}\right).
$$

For each model, we wish to find the value of $x$ after launching where
the height is modeled to be 0. That is how far will the arrow travel
before touching the ground?


For the model without wind resistance, we can graph the function
easily enough. Let's guess the distance is no more than 500 feet:

```
theta = pi/4
j(x) = tan(theta) * x - 16(x/(200cos(theta)))^2
plot(j, 0, 500)
```

Well, we haven't even seen the peak yet. Better to do a little spade
work first. This is a quadratic equation, so we can use the `roots` function:

```
roots(j) 
```


We see that $1250$ is the largest root. So we plot over this domain to visualize the flight:

```
plot(j, 0, 1250)
```

As for the model with `g`, we first define the function. This same
function appeared in a previous example illustrating the use of the
`function` keyword for defining multi-expression functions. We copy
that work here:

```
function g(x; theta = pi/4, k = 1/2)
	 a = 200*cos(theta)
	 b = 32/k
	 tan(theta)*x + (b/a)*x - b*log(a/(a-x))
end
```

A quick plot over the same interval, $[0, 1250]$ yields:

```
plot(g, 0, 1250)
```

Oh, "Domain Error." Of course, when $x \geq a$, the evaluation of
$\log(a/(a-x))$ will fail.  We try on the reduced interval avoiding
the obvious _asymptote_ at `a` by subtracting $1$:

```
a = 200*cos(theta)
plot(g, 0, a - 1) 
```


Now we can see the zero is around 130 to 140. We re-plot:

```
plot(g, 130, 140)
```

Finally, we plot between 134 and 135 and draw the line for $y=0$ to
see the zero clearly:

```
plot([g, x -> 0], 134, 135)
```

The answer is approximately $134.8$


Finally, we plot both graphs at once to see that it was a very windy
day indeed.

```
a = 134.8
plot([j, u -> u < a ? g(u) : NaN] , 0, 1250)
```

```{results="html"}
alert("""

The last two plots used *anonymous* functions to plot. Though a bit confusing to read, such
functions can be very useful for one-off uses.

""")
```


### Practice

#### Question

Graphically estimate the one zero of $f(x) = e^x - x^3$ over the interval $[0,4]$.

```{results="js"}
val = fzero(x -> e^x - x^3, [0,4])
numericq(val, 1e-1)
```



#### Question

Solving equations of the type $f(x)=g(x)$ for $x$ can also be done
graphically. One method is to plot *both* functions and look for
crossing points. Use this approach to graphically estimate all
solutions to $\cos(x) = x^2$ over the interval $(-\pi/2, \pi/2)$. What are they?

```{results="js"}
choices = ["-1.57, 1.57",
	"-0.82, 0.82",
	"0.0"]
ans = 2
radioq(choices, ans)
```



#### Question

In an analysis of rainbows,
[Airy](http://en.wikipedia.org/wiki/Airy_function) developed a special
function implemented as `airy` in `julia`. The zeros are all
negative. The first one is between $-3$ and $-1$. Find it graphically.


```{results="js"}
val = fzero(airy, [-3, -1]);
numericq(val, 1e-1)
```





#### Question

The polynomial $f(x) = x^5 - 6x^3 - 6x^2 -7x - 6$ has three real
roots. Which of the following values is one of them? Try to solve this
graphically.

```{results="js"}
rts =[-2, -1, 3];
x = rts[randperm(3)[1]];
choices = round([x, -5 + 10*rand(2)], 3);
ans = 1;
radioq(choices, ans)
```



```{results="html"}
tabs.next("Bisection algorithm")
```

## Bisection algorithm

The last example had us graphically "zoom" in on a zero, and led us to
an estimate to $1$ or $2$ decimal points. Trying to get more accuracy
than that graphically is at best tedious.  Here we discuss a method to
get as much accuracy as is numerically possible based on the
[intermediate value
theorem](http://en.wikipedia.org/wiki/Intermediate_value_theorem):

> **The intermediate value theorem**: If $f(x)$ is a continuous function
    on $[a,b]$ then at some point in the interval $f(x)$ takes on any
    value between $f(a)$ and $f(b)$. In particular if $f(x)$ is
    continuous with $f(a)$ and $f(b)$ having *different* signs then
    there must be a point $c$ in $[a,b]$ where $f(c) = 0$.





The bisection algorithm is a simple, _iterative_ procedure for finding
such a value $c$ when we have a continuous function and a bracketing
interval.  (When $f(a)$ and $f(b)$ have different signs, we say $a$
and $b$ _bracket_ a root.) 

```{results="html"}
alert("""

The bisection method does not work when the function does not cross
the $x$ axis at the root. For example, the zero at $0$ of $f(x) = x^2
e^x$ would not be found with this method.

""")
```

Mathematically the basic idea is simple.

Starting with $[a,b]$, the midpoint $M = (a + b)/2$, is tested for its
function value. If $f(M) = 0$, great, we are done. If it has opposite
sign of $f(a)$, then a root must be in the interval $[a,M]$, so the
problem is reduced a smaller interval. Otherwise, it has opposite sign
of $f(b)$ and the problem is reduced to $[M,b]$. Either way, the
algorithm is repeated for the smaller interval where a root is
known. As each step halves the interval length, it must eventually
converge to an answer.


Let's take a step for the function $f(x) = x^2 - 2$ over the
interval $[1,2]$. Clearly this interval is a bracketing interval, as
$f(1) = -1$ and $f(2) = 2$. (As well, we can see the answer is around
$1.414$, the square root of $2$.)

```
f(x) = x^2 - 2
a, b = 1, 2
M = (a + b) /2
if f(a) * f(M) < 0
  a, b = a, M
else
  a, b = M, b
end
a,b
```

Here $M=1.5$ and the new interval is $[1.0, 1.5]$. Repeating we should get $[1.25, 1.5]$:

```
M = (a + b) /2
if f(a) * f(M) < 0
  a, b = a, M
else
  a, b = M, b
end
a,b
```


It seems as though we could be here all day. Indeed, if doing this by
hand it might take up quite a bit of time. We should automate this.
Before automating this, we need to think: *when would we stop?*

Mathematically we can keep taking halves using the concept of a
limit. See for example [Zeno's
paradox](http://en.wikipedia.org/wiki/Zenos_paradoxes). On a computer
we don't have such a luxury. In fact, for floating point numbers we
couldn't keep taking halves -- even if we wanted -- as ultimately we
will get `a` and `b` to be floating point values that are next to each
other -- and hence there is no midpoint.

So even though this doesn't make mathematical sense we can stop when the following condition is no longer true:

```
a < M < b
```

A `while` loop is used to repeat the central step until the above is `false`. Our code looks like this:

```
function bisection (f::Function, bracket=Vector)
    a, b = bracket		# bracket is [a,b]
    if f(a) * f(b) > 0
      stop("[a,b] is not a bracket")
    end

    M = (a + b) / 2
    
    while a < M < b
        if f(M) == 0.0
	  break
        end
        ## update step
	if f(a) * f(M) < 0 
	   a, b = a, M
	else
	   a, b = M, b
	end
    end
    M
end
```

To use this, copy and paste the above function definition into a `julia` session.


Okay, let's look at the function $f(x) = -16x^2 + 32x$. We know that 0
and $2$ are roots. Let's see if our algorithm finds them:

```
f(x) = -16x^2 + 32x
bisection(f, [-1, 1]) ## should find 0
```

```
bisection(f, [1, 3])  ## should find 2
```

Okay, it seems to work. Lets try it on a less trivial problem. We know
$\sin(x)$ and $\cos(x)$ cross in the interval $[0, \pi/2]$. If we are
too tired to remember where, we can simply ask:

```
f(x) = cos(x) - sin(x)
x = bisection(f, [0, pi/2])
```

Is `x` really a zero?


```
x, f(x)
```

Hmm, the answer is `1.1102230246251565e-16`. So technically this is not a zero. But *computationally* it is a zero! First it should be clear that it is *really close* to zero. But even more so, it is as close to $0$ as can be possible using floating point values. 

The `nextfloat` and `prevfloat` functions find the floating point values just bigger than `x` and just smaller. In this case we have:

```
f(x) * f(nextfloat(x))
```

So $f$ is crossing sign between the value we found, `x` and the
floating point value just smaller. We can't expect to do any better
than that.



```{results="js"}
example("Graphical and numerical answers")
```


One needs to know where to look in order to use the bisection
method. The basic one-two punch is 

* graph the function to identify quickly values $[a,b]$ which bound a
zero, then

* use the bisection method to find the zero to many decimal points.

Here we illustrate with the problem of finding all intersection points
of $e^x = x^4$ over the interval $[0,10]$. That is, for the function
$f(x) = e^x - x^4$ find the zeros.


A quick plot shows that the function has such a wide range that
looking over the entire domain at once will be problematic:

```
f(x) = exp(x) - x^4
plot(f, 0, 10)
```


Instead, we look between $[0,3]$ and $[8,9]$. A quick confirmation
shows these are good choices to use. For example, between $8$ and $9$
we have:

```
plot(f, 8, 9)     
```

So we find the values of the zero in the bracketed region $[8,9]$:

```
bisection(f, [8, 9])
```

The root within $[0, 3]$ is found with:

```
bisection(f, [0, 3])
```

### The Roots package and fzero

The bisection method, while easy to describe and understand, can be
made more efficient. The `fzero` (**f**unction **zero**) function In the `Roots` package does so. It is used like our `bisection` method -- but does not need to typed in.

For example, to find a root of $f(x) = 2x \cdot \exp(-20) - 2 \cdot
\exp(-20x) + 1$ in the interval $[0,1]$ we have:

```
using Roots
f(x) = 2x*exp(-20) - 2*exp(-20x) + 1
fzero(f, [0, 1])
```


The `fzero` function is actually an interface to different
root-finding algorithms. When called as above (the second argument
being a vector), it uses a bracketing approach as discussed here.

### Problems

#### Question

In the bisection method algorithm we checked that the value of $f$ at
$a$ and $b$ had opposite signs by looking at $f(a)\cdot f(b)$. Why did
this work?

```{results="js"}
choices = ["The product of two numbers is never negative",
	   "The product of 2 numbers with opposite signs is negative, the product of 2 numbers with the same signs is positive",
	   "The product of two numbers will have the sign of the first one."
	  ];
ans = 2;
radioq(choices, ans)
```


#### Question <small>Are there other roots in [-10, 0]?</small>

There is another root in the interval $[-10, 0]$ for the function
$f(x) = e^x - x^4$. Find its value numerically:

```{results="js"}
f(x) = exp(x) - x^2
val = fzero(f, [-10, 0]);
numericq(val, 1e-3)
```


#### Question <small>Relation between $x^2$ and $x \log(x)$</small>


```{hide=true}
```

Let $f(x) = x^2 - 10 \cdot x \cdot \log(x)$. This function has two
zeros on the positive $x$ axis. You are asked to find the largest
(graph and bracket...):


```{results="js"}
b = 10
f(x) =  x^2 - b * x * log(x)
val = fzero(f, [10, 500])
numericq(val, 1e-3)
```
#### Question

The `airy` function has infinitely many negative roots, as the function oscillates when $x < 0$. In a previous problem we graphically found the largest root. Now find the _second largest root_ using the graph to bracket the answer, and then solving.



```{results="js"}
val = fzero(airy, [-5, -4]);
numericq(val, 1e-8)
```




```{results="html"}
tabs.finish()
```
